{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# United States Immigration Data Lake built using Apache Spark\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "We wanted to design a datalake which would aid us in analyzing behaviour of travellers entering the United States. We wanted to understand what factors attract travellers to a certain area such as whether it is low crime rates or large population or a large percentage of foreign born residents. We have therefore gathered all the needed data from various sources and added it to our datalake. This data can be easily read by any data analyst who can then run any query required.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Define the Data Model\n",
    "* Step 3: ETL of i94 Data\n",
    "    * Explore and Assess the data\n",
    "    * Data Wrangling and Cleaning\n",
    "    * Loading onto our datalake\n",
    "* Step 4: ETL of dimension tables\n",
    "    * Explore and Assess the data\n",
    "* Step 5: ETL of US Cities + Population tabe as well as the US Crime data.\n",
    "    * Explore and Assess the data\n",
    "* Step 6: Data Quality Checks and Data Dictionary\n",
    "* Step 7: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "##### Explain what you plan to do in the project in more detail.\n",
    "* In our project we plan on building a datalake which will be used by a team of data scientists and data analysts to study behaviour of people travelling to the United States. Primarily, they want to study why travellers prefer some areas over the others but also our dataset allows them to study year wise patterns. Passengers can also be segregated in different age groups or nationalities.\n",
    "\n",
    "##### What data do you use?\n",
    "* We have used different datasets. Some provided on the udacity workspace and some gathered from elsewhere.\n",
    "\n",
    "##### What is your end solution look like? What tools did you use?\n",
    "* Our end solution is a datalake stored either on Amazon's S3 or local storage as per user's choice and convenience. \n",
    "* For our analytical and wrangling needs we have relied on Apache Spark due to its ease of handling large data and its ability to work with various file formats.\n",
    "* Moreover, where ever possible we have relied on storing our data in the parquet file format. This is a columnar format which allows for high speed reads.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "In our datalake we are using data from different sources.\n",
    "* Our main fact tabe containing large number of immigration events comes from the US National Tourism and Trade Office. There is a dictionary assosiated with this large dataset that we have used to build up a number of smaller dimension tables.\n",
    "* Our next major data source is the us-cities-demographic data. This table contains population demographics of a large number of cities in the United States. This data comes to us from OpenSoft. https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/\n",
    "* Lastly we are using the uscrimes dataset from kaggle. It contains yearly crime rates in major US jurisdictions. https://www.kaggle.com/ayush1498/analysis-of-us-crime-data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Define the Data Model\n",
    "\n",
    "* We will using the i94 events data as our fact table. Our dimension tables will number 7 and these shall be i94addr, i94cit_res, i94mode, i94port, i94visa, uscities, and uscrime.\n",
    "\n",
    "* The data model designed will be as shown in the pic below.\n",
    "\n",
    "![image info](./data_model.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Starting our code by initilizating libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, split, first\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "A config file 'dl.cfg' has been included which contains our AWS account information. Also it contains the location of the s3bucket where we want to store our datalake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "s3bucket = config['AWS']['S3_bucket']\n",
    "localoutput = './outputdata2/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "s3bool = False # If true write to s3bucket given in dl.cfg, if False write to local disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Creating Our Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: ETL of i94 Data\n",
    "* We are going to read in our i94 events data into a spark dataframe. Moreover, this data being in raw farm has to be cleaned and edited before we can store it into our datalake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Reading the parquet files. In the next line we will print the schema of this table to see what columns are present and their data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "path = './sas_data'\n",
    "i94_raw = spark.read.option(\"header\",True).parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Printing the table to see the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "0      CA  20582.0   ...        None        M   1976.0  10292016      F   \n",
       "1      NV  20591.0   ...        None        M   1984.0  10292016      F   \n",
       "\n",
       "  insnum airline        admnum  fltno visatype  \n",
       "0   None      QF  9.495387e+10  00011       B1  \n",
       "1   None      VA  9.495562e+10  00007       B1  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_raw.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We are only interested in a few columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+--------------+\n",
      "|i94res|i94port|i94addr|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|        admnum|\n",
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+--------------+\n",
      "| 438.0|    LOS|     CA|20574.0|    1.0|20582.0|  40.0|    1.0|  1.0|     F|9.495387003E10|\n",
      "| 438.0|    LOS|     NV|20574.0|    1.0|20591.0|  32.0|    1.0|  1.0|     F|9.495562283E10|\n",
      "+------+-------+-------+-------+-------+-------+------+-------+-----+------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_raw.select(\"i94res\",\"i94port\",\"i94addr\", \"arrdate\",\"i94mode\",\"depdate\",\"i94bir\",\"i94visa\",\"count\" \\\n",
    "                  ,\"gender\",\"admnum\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let us now correct the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94fact = i94_raw.select(col(\"cicid\").cast(IntegerType()),col(\"i94res\").cast(IntegerType()),col(\"i94port\"),\n",
    "                           col(\"arrdate\").cast(IntegerType()), \\\n",
    "                           col(\"i94mode\").cast(IntegerType()), col(\"i94addr\"), col(\"depdate\").cast(IntegerType()),\n",
    "                           col(\"i94bir\").cast(IntegerType()),col(\"i94visa\").cast(IntegerType()), \n",
    "                           col(\"count\").cast(IntegerType()), \\\n",
    "                              \"gender\",col(\"admnum\").cast(LongType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "|  cicid|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|gender|     admnum|\n",
      "+-------+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "|5748517|   438|    LOS|  20574|      1|     CA|  20582|    40|      1|    1|     F|94953870030|\n",
      "|5748518|   438|    LOS|  20574|      1|     NV|  20591|    32|      1|    1|     F|94955622830|\n",
      "+-------+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94fact.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Convert arrdate and depdate into proper datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dt_formatter = udf(lambda x: (dt.datetime(1960, 1, 1).date() + dt.timedelta(x)).isoformat() if x else None)\n",
    "i94fact = i94fact.withColumn(\"arrival_date\", dt_formatter(i94fact.arrdate))\n",
    "i94fact = i94fact.withColumn(\"departure_date\", dt_formatter(i94fact.depdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----------+------------+--------------+\n",
      "|  cicid|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|gender|     admnum|arrival_date|departure_date|\n",
      "+-------+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----------+------------+--------------+\n",
      "|5748517|   438|    LOS|  20574|      1|     CA|  20582|    40|      1|    1|     F|94953870030|  2016-04-30|    2016-05-08|\n",
      "|5748518|   438|    LOS|  20574|      1|     NV|  20591|    32|      1|    1|     F|94955622830|  2016-04-30|    2016-05-17|\n",
      "+-------+------+-------+-------+-------+-------+-------+------+-------+-----+------+-----------+------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94fact.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Seems to have worked all good. Now we will drop the arrdate and depdate columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94fact = i94fact.drop('arrdate','depdate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Out data has been cleaned out, we will write the table into our datalake in parquet format paritioned by arrival month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# first add arrival month column to the sparkdf.\n",
    "i94fact = i94fact.withColumn(\"arrival_month\", date_format('arrival_date','M'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Writing the files\n",
    "\n",
    "if s3bool:\n",
    "    i94fact.write.option(\"header\",True).partitionBy(\"arrival_month\").mode(\"overwrite\").parquet(s3bucket+\"i94fact\")\n",
    "    \n",
    "else:\n",
    "    i94fact.write.option(\"header\",True).partitionBy(\"arrival_month\").mode(\"overwrite\").parquet(localoutput+\"i94fact\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: ETL of dimension tables\n",
    "Now we must read the I94_SAS_Labels_Descriptions.SAS and extract important information which will help us make sense of our fact tabe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# From https://knowledge.udacity.com/questions/125439\n",
    "\n",
    "\n",
    "with open('./I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    f_content = f.read()\n",
    "    f_content = f_content.replace('\\t', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This function will read the contents of the descriptions file and load them into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# From https://knowledge.udacity.com/questions/125439\n",
    "\n",
    "def code_mapper(file, idx):\n",
    "    f_content2 = f_content[f_content.index(idx):]\n",
    "    f_content2 = f_content2[:f_content2.index(';')].split('\\n')\n",
    "    f_content2 = [i.replace(\"'\", \"\") for i in f_content2]\n",
    "    dic = [i.split('=') for i in f_content2[1:]]\n",
    "    dic = dict([i[0].strip(), i[1].strip()] for i in dic if len(i) == 2)\n",
    "    \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94cit_res = code_mapper(f_content, \"i94cntyl\")\n",
    "\n",
    "i94port = code_mapper(f_content, \"i94prtl\")\n",
    "\n",
    "i94mode = code_mapper(f_content, \"i94model\")\n",
    "\n",
    "i94addr = code_mapper(f_content, \"i94addrl\")\n",
    "\n",
    "i94visa = {'1':'Business', '2': 'Pleasure', '3' : 'Student'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Transformation and Loading of  i94port to a Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+\n",
      "|city_code|           city_name|state_name|\n",
      "+---------+--------------------+----------+\n",
      "|      ALC|               ALCAN|        AK|\n",
      "|      ANC|           ANCHORAGE|        AK|\n",
      "|      BAR|BAKER AAF - BAKER...|        AK|\n",
      "|      DAC|       DALTONS CACHE|        AK|\n",
      "|      PIZ|DEW STATION PT LA...|        AK|\n",
      "+---------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(i94port, orient='index', columns=['city_and_state'])\n",
    "df = df.reset_index().rename(columns={'index': 'city_code'})\n",
    "i94port_sparkDF=spark.createDataFrame(df) \n",
    "split_col = F.split(i94port_sparkDF['city_and_state'], ',')\n",
    "i94port_sparkDF = i94port_sparkDF.withColumn('city_name', split_col.getItem(0))\n",
    "i94port_sparkDF = i94port_sparkDF.withColumn('state_name', split_col.getItem(1))\n",
    "i94port_sparkDF = i94port_sparkDF.drop('city_and_state')\n",
    "i94port_sparkDF.show(5)\n",
    "\n",
    "# Writing the table as a json file into our datalake\n",
    "if s3bool:\n",
    "    i94port_sparkDF.write.option(\"header\",True).partitionBy(\"state_name\").mode(\"overwrite\").json(s3bucket+\"i94port\")\n",
    "else:\n",
    "    i94port_sparkDF.write.option(\"header\",True).partitionBy(\"state_name\").mode(\"overwrite\").json(localoutput+\"i94port\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Transformation and Loading of  i94cit_res to a Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|res_code|country_of_residence|\n",
      "+--------+--------------------+\n",
      "|     582|MEXICO Air Sea, a...|\n",
      "|     236|         AFGHANISTAN|\n",
      "|     101|             ALBANIA|\n",
      "|     316|             ALGERIA|\n",
      "|     102|             ANDORRA|\n",
      "+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(i94cit_res, orient='index', columns=['country_of_residence'])\n",
    "df = df.reset_index().rename(columns={'index': 'res_code'})\n",
    "i94cit_res_sparkDF=spark.createDataFrame(df) \n",
    "i94cit_res_sparkDF.show(5)\n",
    "\n",
    "if s3bool:\n",
    "    i94cit_res_sparkDF.write.option(\"header\",True).mode(\"overwrite\").json(s3bucket+\"i94cit_res\")\n",
    "else:\n",
    "    i94cit_res_sparkDF.write.option(\"header\",True).mode(\"overwrite\").json(localoutput+\"i94cit_res\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Transformation and Loading of  i94mode to a Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+\n",
      "|i94mode_code|mode_of_travel|\n",
      "+------------+--------------+\n",
      "|           1|           Air|\n",
      "|           2|           Sea|\n",
      "|           3|          Land|\n",
      "|           9|  Not reported|\n",
      "+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(i94mode, orient='index', columns=['mode_of_travel'])\n",
    "df = df.reset_index().rename(columns={'index' : 'i94mode_code'})\n",
    "i94mode_sparkDF = spark.createDataFrame(df)\n",
    "i94mode_sparkDF.show()\n",
    "\n",
    "if s3bool:\n",
    "    i94mode_sparkDF.write.option(\"header\",True).mode(\"overwrite\").json(s3bucket+\"i94mode\")\n",
    "else:\n",
    "    i94mode_sparkDF.write.option(\"header\",True).mode(\"overwrite\").json(localoutput+\"i94mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Transformation and Loading of  i94addr to a Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+\n",
      "|i94addr_code|residence_address|\n",
      "+------------+-----------------+\n",
      "|          AL|          ALABAMA|\n",
      "|          AK|           ALASKA|\n",
      "|          AZ|          ARIZONA|\n",
      "|          AR|         ARKANSAS|\n",
      "|          CA|       CALIFORNIA|\n",
      "+------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(i94addr, orient='index', columns=['residence_address'])\n",
    "df = df.reset_index().rename(columns={'index':'i94addr_code'})\n",
    "i94addr_sparkDF = spark.createDataFrame(df)\n",
    "i94addr_sparkDF.show(5)\n",
    "\n",
    "if s3bool:\n",
    "    i94addr_sparkDF.write.option(\"header\",True).mode(\"overwrite\").json(s3bucket+\"i94addr\")\n",
    "else:\n",
    "    i94addr_sparkDF.write.option(\"header\",True).mode(\"overwrite\").json(localoutput+\"i94addr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Transformation and Loading of  i94visa to a Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|visa_code|visa_type|\n",
      "+---------+---------+\n",
      "|        1| Business|\n",
      "|        2| Pleasure|\n",
      "|        3|  Student|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(i94visa, orient='index', columns=['visa_type'])\n",
    "df = df.reset_index().rename(columns={'index':'visa_code'})\n",
    "i94visa_sparkDF = spark.createDataFrame(df)\n",
    "i94visa_sparkDF.show()\n",
    "if s3bool:\n",
    "    i94visa_sparkDF.write.option(\"header\",True).mode(\"overwrite\").json(s3bucket+\"i94visa\")\n",
    "else:\n",
    "    i94visa_sparkDF.write.option(\"header\",True).mode(\"overwrite\").json(localoutput+\"i94visa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 5: ETL of US Cities + Population tabe as well as the US Crime data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Reading the data into a spark dataframe. It is not a usual csv file seperated by commas. It is instead seperated by semi colons and hence that has to mentioned in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "uscities_df=spark.read.csv(\"./us-cities-demographics.csv\", sep=';', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Princting the schema to see the columns present and their data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uscities_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Printing the values to sneakpeak into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State Median Age Male Population Female Population  \\\n",
       "0  Silver Spring       Maryland       33.8           40601             41862   \n",
       "1         Quincy  Massachusetts       41.0           44129             49500   \n",
       "2         Hoover        Alabama       38.5           38040             46799   \n",
       "\n",
       "  Total Population Number of Veterans Foreign-born Average Household Size  \\\n",
       "0            82463               1562        30908                    2.6   \n",
       "1            93629               4147        32935                   2.39   \n",
       "2            84839               4819         8229                   2.58   \n",
       "\n",
       "  State Code                Race  Count  \n",
       "0         MD  Hispanic or Latino  25924  \n",
       "1         MA               White  58723  \n",
       "2         AL               Asian   4759  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uscities_df.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Looking for duplicate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>3917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>30473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     City          State Median Age Male Population Female Population  \\\n",
       "0  Quincy  Massachusetts       41.0           44129             49500   \n",
       "1  Quincy  Massachusetts       41.0           44129             49500   \n",
       "2  Quincy  Massachusetts       41.0           44129             49500   \n",
       "3  Quincy  Massachusetts       41.0           44129             49500   \n",
       "4  Quincy  Massachusetts       41.0           44129             49500   \n",
       "\n",
       "  Total Population Number of Veterans Foreign-born Average Household Size  \\\n",
       "0            93629               4147        32935                   2.39   \n",
       "1            93629               4147        32935                   2.39   \n",
       "2            93629               4147        32935                   2.39   \n",
       "3            93629               4147        32935                   2.39   \n",
       "4            93629               4147        32935                   2.39   \n",
       "\n",
       "  State Code                               Race  Count  \n",
       "0         MA                              White  58723  \n",
       "1         MA                 Hispanic or Latino   2566  \n",
       "2         MA  American Indian and Alaska Native    351  \n",
       "3         MA          Black or African-American   3917  \n",
       "4         MA                              Asian  30473  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uscities_df.where(\"city == 'Quincy'\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The above results shows that each city is entered multiple times with different ethnicites population mentioned seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "uscities_df.createOrReplaceTempView(\"uscities_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+\n",
      "|total_city_entries|different_cities|\n",
      "+------------------+----------------+\n",
      "|              2891|             567|\n",
      "+------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "    SELECT COUNT(City) AS total_city_entries, COUNT(DISTINCT(City)) as different_cities\n",
    "    FROM uscities_table\n",
    "\n",
    "\"\"\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now taking out only the columns required with select. Next we are going to eliminate duplicate entries for cities by turning different ethnicity rows into different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "uscities_withrace_df=(uscities_df.select(\"city\",\"state code\",\"Total Population\",\"Foreign-born\", \"Race\",\"count\").groupby(uscities_df.City, \"state code\", \"Total Population\", \"Foreign-born\").pivot(\"Race\").agg(first(\"Count\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uscities_withrace_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The difference in count and distinct(cities) can be attributed to different cities with the same name but in different states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- state code: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- American Indian and Alaska Native: string (nullable = true)\n",
      " |-- Asian: string (nullable = true)\n",
      " |-- Black or African-American: string (nullable = true)\n",
      " |-- Hispanic or Latino: string (nullable = true)\n",
      " |-- White: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uscities_withrace_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Changing Column names to make using Spark SQL easier in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+----------------+----------+---------+------+------------+---------+\n",
      "| city_name|state_code|total_pop|foreign_born_pop|native_pop|asian_pop|aa_pop|hispanic_pop|white_pop|\n",
      "+----------+----------+---------+----------------+----------+---------+------+------------+---------+\n",
      "|Framingham|        MA|    71210|           19070|       849|     5993|  6944|       13000|    52205|\n",
      "| Rock Hill|        SC|    71567|            2413|       610|     1073| 28204|        2845|    41652|\n",
      "+----------+----------+---------+----------------+----------+---------+------+------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uscities_withrace_df = uscities_withrace_df.withColumnRenamed(\"city\",\"city_name\")\\\n",
    "                    .withColumnRenamed(\"American Indian and Alaska Native\",\"native_pop\")\\\n",
    "                    .withColumnRenamed(\"state code\",\"state_code\")\\\n",
    "                    .withColumnRenamed(\"Total Population\",\"total_pop\")\\\n",
    "                    .withColumnRenamed(\"Asian\",\"asian_pop\")\\\n",
    "                    .withColumnRenamed(\"Black or African-American\",\"aa_pop\")\\\n",
    "                    .withColumnRenamed(\"Hispanic or Latino\",\"hispanic_pop\")\\\n",
    "                    .withColumnRenamed(\"White\",\"white_pop\")\\\n",
    "                    .withColumnRenamed(\"Foreign-born\",\"foreign_born_pop\")\n",
    "\n",
    "uscities_withrace_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we must change the string types to Integer for easier calculation in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "uscities_withrace_df = uscities_withrace_df.select(col(\"city_name\"), col(\"state_code\"), col(\"total_pop\").cast(IntegerType()),\\\n",
    "                            col(\"native_pop\").cast(IntegerType()),\\\n",
    "                            col(\"asian_pop\").cast(IntegerType()),\\\n",
    "                            col(\"aa_pop\").cast(IntegerType()),\\\n",
    "                            col(\"hispanic_pop\").cast(IntegerType()),\\\n",
    "                            col(\"white_pop\").cast(IntegerType()),\\\n",
    "                            col(\"foreign_born_pop\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Printing out the data to see if everything is good to proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city_name: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- total_pop: integer (nullable = true)\n",
      " |-- native_pop: integer (nullable = true)\n",
      " |-- asian_pop: integer (nullable = true)\n",
      " |-- aa_pop: integer (nullable = true)\n",
      " |-- hispanic_pop: integer (nullable = true)\n",
      " |-- white_pop: integer (nullable = true)\n",
      " |-- foreign_born_pop: integer (nullable = true)\n",
      "\n",
      "+----------+----------+---------+----------+---------+------+------------+---------+----------------+\n",
      "| city_name|state_code|total_pop|native_pop|asian_pop|aa_pop|hispanic_pop|white_pop|foreign_born_pop|\n",
      "+----------+----------+---------+----------+---------+------+------------+---------+----------------+\n",
      "|Framingham|        MA|    71210|       849|     5993|  6944|       13000|    52205|           19070|\n",
      "| Rock Hill|        SC|    71567|       610|     1073| 28204|        2845|    41652|            2413|\n",
      "+----------+----------+---------+----------+---------+------+------------+---------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uscities_withrace_df.printSchema()\n",
    "uscities_withrace_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Output the data from uscities_withrace_df into our datalake in the parquet format. It will be paritioned on the \"state_code\" column to make for more efficient reading later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "if s3bool:\n",
    "    uscities_withrace_df.write.option(\"header\",True).partitionBy(\"state_code\").mode(\"overwrite\").parquet(s3bucket+\"uscities\")\n",
    "else:\n",
    "    uscities_withrace_df.write.option(\"header\",True).partitionBy(\"state_code\").mode(\"overwrite\").parquet(localoutput+\"uscities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### ETL on the US Crime Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Reading the data from a csv file stored locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "uscrime_df=spark.read.csv(\"./uscrime.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Printing the schema to see what the csv file contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- report_year: string (nullable = true)\n",
      " |-- agency_code: string (nullable = true)\n",
      " |-- agency_jurisdiction: string (nullable = true)\n",
      " |-- population: string (nullable = true)\n",
      " |-- violent_crimes: string (nullable = true)\n",
      " |-- homicides: string (nullable = true)\n",
      " |-- rapes: string (nullable = true)\n",
      " |-- assaults: string (nullable = true)\n",
      " |-- robberies: string (nullable = true)\n",
      " |-- months_reported: string (nullable = true)\n",
      " |-- crimes_percapita: string (nullable = true)\n",
      " |-- homicides_percapita: string (nullable = true)\n",
      " |-- rapes_percapita: string (nullable = true)\n",
      " |-- assaults_percapita: string (nullable = true)\n",
      " |-- robberies_percapita: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uscrime_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Viewing the contents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_year</th>\n",
       "      <th>agency_code</th>\n",
       "      <th>agency_jurisdiction</th>\n",
       "      <th>population</th>\n",
       "      <th>violent_crimes</th>\n",
       "      <th>homicides</th>\n",
       "      <th>rapes</th>\n",
       "      <th>assaults</th>\n",
       "      <th>robberies</th>\n",
       "      <th>months_reported</th>\n",
       "      <th>crimes_percapita</th>\n",
       "      <th>homicides_percapita</th>\n",
       "      <th>rapes_percapita</th>\n",
       "      <th>assaults_percapita</th>\n",
       "      <th>robberies_percapita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975</td>\n",
       "      <td>NM00101</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>286238</td>\n",
       "      <td>2383</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>1353</td>\n",
       "      <td>819</td>\n",
       "      <td>12</td>\n",
       "      <td>832.52</td>\n",
       "      <td>10.48</td>\n",
       "      <td>63.23</td>\n",
       "      <td>472.68</td>\n",
       "      <td>286.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>TX22001</td>\n",
       "      <td>Arlington, TX</td>\n",
       "      <td>112478</td>\n",
       "      <td>278</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>132</td>\n",
       "      <td>113</td>\n",
       "      <td>12</td>\n",
       "      <td>247.16</td>\n",
       "      <td>4.45</td>\n",
       "      <td>24.89</td>\n",
       "      <td>117.36</td>\n",
       "      <td>100.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  report_year agency_code agency_jurisdiction population violent_crimes  \\\n",
       "0        1975     NM00101     Albuquerque, NM     286238           2383   \n",
       "1        1975     TX22001       Arlington, TX     112478            278   \n",
       "\n",
       "  homicides rapes assaults robberies months_reported crimes_percapita  \\\n",
       "0        30   181     1353       819              12           832.52   \n",
       "1         5    28      132       113              12           247.16   \n",
       "\n",
       "  homicides_percapita rapes_percapita assaults_percapita robberies_percapita  \n",
       "0               10.48           63.23             472.68              286.13  \n",
       "1                4.45           24.89             117.36              100.46  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uscrime_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We need to first do proper conversion of strings to integer and double type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "uscrime_df = uscrime_df.select(col(\"report_year\").cast(IntegerType()), col(\"agency_code\"), col(\"agency_jurisdiction\"),\\\n",
    "                               col(\"population\").cast(IntegerType()),\\\n",
    "                               col(\"violent_crimes\").cast(IntegerType()),\\\n",
    "                               col(\"homicides\").cast(IntegerType()),\\\n",
    "                               col(\"rapes\").cast(IntegerType()),\\\n",
    "                               col(\"assaults\").cast(IntegerType()),\\\n",
    "                               col(\"robberies\").cast(IntegerType()),\\\n",
    "                               col(\"months_reported\").cast(IntegerType()),\\\n",
    "                               col(\"crimes_percapita\").cast(FloatType()),\\\n",
    "                               col(\"homicides_percapita\").cast(FloatType()),\\\n",
    "                               col(\"rapes_percapita\").cast(FloatType()),\\\n",
    "                               col(\"assaults_percapita\").cast(FloatType()),\\\n",
    "                               col(\"robberies_percapita\").cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- report_year: integer (nullable = true)\n",
      " |-- agency_code: string (nullable = true)\n",
      " |-- agency_jurisdiction: string (nullable = true)\n",
      " |-- population: integer (nullable = true)\n",
      " |-- violent_crimes: integer (nullable = true)\n",
      " |-- homicides: integer (nullable = true)\n",
      " |-- rapes: integer (nullable = true)\n",
      " |-- assaults: integer (nullable = true)\n",
      " |-- robberies: integer (nullable = true)\n",
      " |-- months_reported: integer (nullable = true)\n",
      " |-- crimes_percapita: float (nullable = true)\n",
      " |-- homicides_percapita: float (nullable = true)\n",
      " |-- rapes_percapita: float (nullable = true)\n",
      " |-- assaults_percapita: float (nullable = true)\n",
      " |-- robberies_percapita: float (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_year</th>\n",
       "      <th>agency_code</th>\n",
       "      <th>agency_jurisdiction</th>\n",
       "      <th>population</th>\n",
       "      <th>violent_crimes</th>\n",
       "      <th>homicides</th>\n",
       "      <th>rapes</th>\n",
       "      <th>assaults</th>\n",
       "      <th>robberies</th>\n",
       "      <th>months_reported</th>\n",
       "      <th>crimes_percapita</th>\n",
       "      <th>homicides_percapita</th>\n",
       "      <th>rapes_percapita</th>\n",
       "      <th>assaults_percapita</th>\n",
       "      <th>robberies_percapita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975</td>\n",
       "      <td>NM00101</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>286238</td>\n",
       "      <td>2383</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>1353</td>\n",
       "      <td>819</td>\n",
       "      <td>12</td>\n",
       "      <td>832.520020</td>\n",
       "      <td>10.48</td>\n",
       "      <td>63.230000</td>\n",
       "      <td>472.679993</td>\n",
       "      <td>286.130005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>TX22001</td>\n",
       "      <td>Arlington, TX</td>\n",
       "      <td>112478</td>\n",
       "      <td>278</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>132</td>\n",
       "      <td>113</td>\n",
       "      <td>12</td>\n",
       "      <td>247.160004</td>\n",
       "      <td>4.45</td>\n",
       "      <td>24.889999</td>\n",
       "      <td>117.360001</td>\n",
       "      <td>100.459999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   report_year agency_code agency_jurisdiction  population  violent_crimes  \\\n",
       "0         1975     NM00101     Albuquerque, NM      286238            2383   \n",
       "1         1975     TX22001       Arlington, TX      112478             278   \n",
       "\n",
       "   homicides  rapes  assaults  robberies  months_reported  crimes_percapita  \\\n",
       "0         30    181      1353        819               12        832.520020   \n",
       "1          5     28       132        113               12        247.160004   \n",
       "\n",
       "   homicides_percapita  rapes_percapita  assaults_percapita  \\\n",
       "0                10.48        63.230000          472.679993   \n",
       "1                 4.45        24.889999          117.360001   \n",
       "\n",
       "   robberies_percapita  \n",
       "0           286.130005  \n",
       "1           100.459999  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uscrime_df.printSchema()\n",
    "uscrime_df.limit(2).toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now that our schema looks alright, we must seperate the agency_jurisdiction to make seperate city and state columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_year</th>\n",
       "      <th>agency_code</th>\n",
       "      <th>population</th>\n",
       "      <th>violent_crimes</th>\n",
       "      <th>homicides</th>\n",
       "      <th>rapes</th>\n",
       "      <th>assaults</th>\n",
       "      <th>robberies</th>\n",
       "      <th>months_reported</th>\n",
       "      <th>crimes_percapita</th>\n",
       "      <th>homicides_percapita</th>\n",
       "      <th>rapes_percapita</th>\n",
       "      <th>assaults_percapita</th>\n",
       "      <th>robberies_percapita</th>\n",
       "      <th>city_name</th>\n",
       "      <th>state_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975</td>\n",
       "      <td>NM00101</td>\n",
       "      <td>286238</td>\n",
       "      <td>2383</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>1353</td>\n",
       "      <td>819</td>\n",
       "      <td>12</td>\n",
       "      <td>832.520020</td>\n",
       "      <td>10.48</td>\n",
       "      <td>63.230000</td>\n",
       "      <td>472.679993</td>\n",
       "      <td>286.130005</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>TX22001</td>\n",
       "      <td>112478</td>\n",
       "      <td>278</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>132</td>\n",
       "      <td>113</td>\n",
       "      <td>12</td>\n",
       "      <td>247.160004</td>\n",
       "      <td>4.45</td>\n",
       "      <td>24.889999</td>\n",
       "      <td>117.360001</td>\n",
       "      <td>100.459999</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   report_year agency_code  population  violent_crimes  homicides  rapes  \\\n",
       "0         1975     NM00101      286238            2383         30    181   \n",
       "1         1975     TX22001      112478             278          5     28   \n",
       "\n",
       "   assaults  robberies  months_reported  crimes_percapita  \\\n",
       "0      1353        819               12        832.520020   \n",
       "1       132        113               12        247.160004   \n",
       "\n",
       "   homicides_percapita  rapes_percapita  assaults_percapita  \\\n",
       "0                10.48        63.230000          472.679993   \n",
       "1                 4.45        24.889999          117.360001   \n",
       "\n",
       "   robberies_percapita    city_name state_code  \n",
       "0           286.130005  Albuquerque         NM  \n",
       "1           100.459999    Arlington         TX  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_col = F.split(uscrime_df['agency_jurisdiction'], ', ')\n",
    "uscrime_df = uscrime_df.withColumn('city_name', split_col.getItem(0))\n",
    "uscrime_df = uscrime_df.withColumn('state_code', split_col.getItem(1))\n",
    "uscrime_df = uscrime_df.drop('agency_jurisdiction')\n",
    "uscrime_df.limit(2).toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Re ordering the columns to bring city_name and state_code in front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "uscrime_df = uscrime_df.select([\"city_name\",\"state_code\",\"report_year\",\"agency_code\",\"population\",\"violent_crimes\",\\\n",
    "                                \"homicides\",\"rapes\",\"assaults\",\"robberies\",\"months_reported\",\"crimes_percapita\",\"homicides_percapita\",\\\n",
    "                                \"rapes_percapita\",\"assaults_percapita\",\"robberies_percapita\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Writing the table as a parquet into our datalake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "if s3bool:\n",
    "    uscrime_df.write.option(\"header\",True).mode(\"overwrite\").parquet(s3bucket+\"uscrime\")\n",
    "else:\n",
    "    uscrime_df.write.option(\"header\",True).mode(\"overwrite\").parquet(localoutput+\"uscrime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 6: Data Quality Checks and Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Quality Checks\n",
    "We need to include a few data quality checks to ensure our pipeline is working properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**1. First we can check our uscrime data to see that there are no duplicate values entered.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+-----+\n",
      "|city_name|state_code|report_year|count|\n",
      "+---------+----------+-----------+-----+\n",
      "+---------+----------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uscrime_df.groupBy(\"city_name\",\"state_code\",\"report_year\").count().filter(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The empty results above show no duplicate value for any city for a particular year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**2. Now let us check to see if there are any duplicate city values in our uscities data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+\n",
      "|city_name|state_code|count|\n",
      "+---------+----------+-----+\n",
      "+---------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uscities_withrace_df.groupBy(\"city_name\",\"state_code\").count().filter(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The empty results show no duplicate values for any city in our uscities date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**3. Check to see no NULL value for the primary key in our main facts table.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-------+-------+-------+------+-------+-----+------+------+------------+--------------+-------------+\n",
      "|cicid|i94res|i94port|i94mode|i94addr|i94bir|i94visa|count|gender|admnum|arrival_date|departure_date|arrival_month|\n",
      "+-----+------+-------+-------+-------+------+-------+-----+------+------+------------+--------------+-------------+\n",
      "+-----+------+-------+-------+-------+------+-------+-----+------+------+------------+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94fact.where(\"cicid IS NULL\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Empty results show no such row where cicid is NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Dictionary\n",
    "Let us now include a data dictionary for all our tables.\n",
    "\n",
    "1. i94fact\n",
    "    * cicid - primary key of our fact table. a unique identifier for each row of data, stored as an integer.\n",
    "    * i94res - this value identifies the country of residence of the traveller.\n",
    "    * i94port - this value identifies the port of arrival of the traveller.\n",
    "    * i94mode - the mode of transport of the traveller.\n",
    "    * i94addr - the address mentioned by the traveller in the united states where he or she will be staying on their trip.\n",
    "    * i94bir - the age of the traveller at the time of the trip.\n",
    "    * i94visa - the visa type of the traveller.\n",
    "    * count\n",
    "    * gender\n",
    "    * admnum - admission number assigned\n",
    "    * arrival_date\n",
    "    * departure_date\n",
    "2. i94port\n",
    "    * city_code - primary key to identify city\n",
    "    * city_name\n",
    "    * state_code\n",
    "3. i94cit_res\n",
    "    * res_code - primary key to identify the country of original residence\n",
    "    * country_of_residence - string value\n",
    "4. i94mode\n",
    "    * i94mode_code - primary key\n",
    "    * mode_of_travel - mode of travel in string value\n",
    "5. i94addr\n",
    "    * i94addr_code - primary key\n",
    "    * residence_address\n",
    "6. i94visa\n",
    "    * visa_code - primary key\n",
    "    * visa_type - type visa - either business, pleasure or student\n",
    "7. uscities\n",
    "    * city_name - name of the city in string\n",
    "    * state_code - 2 letter code for the state\n",
    "    * total_pop - total population of the city\n",
    "    * native_pop - population of native americans\n",
    "    * asian_pop - population of asian americans\n",
    "    * aa_pop - population of african americans\n",
    "    * hispanic_pop - population of hispanics\n",
    "    * white_pop - population of whites\n",
    "    * foreign_born_pop - population of residents of the city who were born outside the United States\n",
    "8. uscrime\n",
    "    * city_name \n",
    "    * state_code\n",
    "    * report_year - the year for which statistics are given\n",
    "    * agency_code - the agency which reported the statistics\n",
    "    * population\n",
    "    * violent_crimes - number of violent crimes in the year\n",
    "    * homicides - number of homicide crimes\n",
    "    * rapes - number of rapes\n",
    "    * assaults - number of assaults\n",
    "    * robberies - number of robberies\n",
    "    * months_reported - the number of months in a year for which the data is reported\n",
    "    * crimes_percapita - total crimes divided by the population\n",
    "    * homicides_percapita\n",
    "    * rapes_percapita\n",
    "    * robberies_percapita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 7: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "    - For our dataengineering capstone project. We have designed a datalake stored on either Amazon's S3 service or a local folder depending on data requirements. We have used Apache Spark to transform and wrangle our data due to the large size of the fact table. (More than 3 million rows). Apache Spark being a distributed software can easily handle large data and perform much better than pandas library.\n",
    "    - Moreover, in our datalake all files have been stored in the parquet format.\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "    - Taking a general use case, the fact table can be updated once or twice a day depending on the volume of events generated. The frequency can also be increased as per business demand.\n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    "\n",
    " * The data was increased by 100x.\n",
    "    - If the data were to be increased by 100x then the Apache Spark program should be run on Amazon's EMR cluster on AWS. The number of nodes should be high as well as their processing power. This will ensure fast wrangling of the data.\n",
    "    - Also, the \"s3bool\" trigger should be set to True, this will write the output to a datalake on Amazon's S3 service which has near unlimited storage.\n",
    "\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "    - If the data must be updated every day by 7am then the best solution would be to run the commands on an Apache Airflow dashboard.\n",
    "    - Different functions performed in this notebook can be divided into tasks and subtasks. Each of these can be scheduled as per their dependencies on AirFlow. Moreover, Airflow will also allow us to parallelize different functions that are not dependent on each other. Another useful feature of AirFlow is email reminders to update us on the status of the pipeline operation.\n",
    "\n",
    " * The database needed to be accessed by 100+ people.\n",
    " \n",
    "    - An S3 data lake is the best way to make the data accessible for a large number of people. If we were to instead populate an RDBS on Amazon Redshift, we would incur high cost of data transfer. Moreover their will be a slowing down of each query due to overload.\n",
    "    - Plus we will also create IAM roles for different departments on AWS to ensure segregation of policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
